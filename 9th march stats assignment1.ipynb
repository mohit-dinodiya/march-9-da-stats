{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff30fdea-8219-4b60-8f8d-a7121ac8d50d",
   "metadata": {},
   "source": [
    "# Q1: What are the Probability Mass Function (PMF) and Probability Density Function (PDF)? Explain with an example.\n",
    "\n",
    "Probability Mass Function (PMF) and Probability Density Function (PDF) are two concepts in probability theory that are used to describe the probability distribution of a random variable.\n",
    "\n",
    "The PMF is used for discrete random variables, which are variables that can only take on a countable set of values. The PMF is defined as the function that gives the probability of a particular value of the discrete random variable. That is, if X is a discrete random variable, then the PMF of X is given by:\n",
    "\n",
    "P(X = x)\n",
    "\n",
    "Where P is the probability function and x is a specific value that X can take on.\n",
    "\n",
    "For example, consider the random variable X that represents the outcome of a fair six-sided die roll. The PMF of X can be calculated as follows:\n",
    "\n",
    "P(X = 1) = 1/6\n",
    "P(X = 2) = 1/6\n",
    "P(X = 3) = 1/6\n",
    "P(X = 4) = 1/6\n",
    "P(X = 5) = 1/6\n",
    "P(X = 6) = 1/6\n",
    "\n",
    "This means that the probability of rolling a 1, 2, 3, 4, 5, or 6 is each 1/6.\n",
    "\n",
    "The PDF, on the other hand, is used for continuous random variables, which are variables that can take on any value within a continuous range. The PDF is defined as the function that gives the probability density of the continuous random variable. That is, if X is a continuous random variable, then the PDF of X is given by:\n",
    "\n",
    "f(x)\n",
    "\n",
    "Where f is the probability density function and x is a specific value that X can take on.\n",
    "\n",
    "For example, consider the random variable Y that represents the height of adult females in a certain population. The PDF of Y can be calculated as follows:\n",
    "\n",
    "f(y) = k e^(-0.5(y-μ)^2/σ^2)\n",
    "\n",
    "Where k is a constant that ensures that the total area under the PDF is equal to 1, μ is the mean height of adult females in the population, and σ is the standard deviation of their heights.\n",
    "\n",
    "This PDF describes the probability density of female heights in the population. The probability of a female having a height between y1 and y2 can be calculated by integrating the PDF between y1 and y2:\n",
    "\n",
    "P(y1 ≤ Y ≤ y2) = ∫(y1 to y2) f(y) dy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7653a06-9949-4762-9e8a-66c4d107a2d7",
   "metadata": {},
   "source": [
    "# Q2: What is Cumulative Density Function (CDF)? Explain with an example. Why CDF is used?\n",
    "\n",
    "The Cumulative Distribution Function (CDF) is a function used in probability theory that describes the probability of a random variable taking a value less than or equal to a specified value. The CDF is defined for both discrete and continuous random variables.\n",
    "\n",
    "For a discrete random variable X, the CDF is given by:\n",
    "\n",
    "F(x) = P(X ≤ x)\n",
    "\n",
    "For a continuous random variable X, the CDF is given by:\n",
    "\n",
    "F(x) = ∫(-∞ to x) f(t) dt\n",
    "\n",
    "where f(t) is the Probability Density Function (PDF) of X.\n",
    "\n",
    "The CDF is used to describe the probability distribution of a random variable and to calculate probabilities associated with that distribution. For example, the CDF can be used to calculate the probability of a random variable taking on a value within a certain range or above a certain threshold.\n",
    "\n",
    "For example, consider the random variable X that represents the outcome of a coin toss. X takes on the value 0 for tails and 1 for heads. The CDF of X can be calculated as follows:\n",
    "\n",
    "F(x) = P(X ≤ x)\n",
    "F(0) = P(X ≤ 0) = P(X = 0) = 0.5\n",
    "F(1) = P(X ≤ 1) = P(X = 0) + P(X = 1) = 0.5 + 0.5 = 1\n",
    "\n",
    "This means that the probability of getting tails is 0.5, the probability of getting heads is 0.5, and the probability of getting a value less than or equal to 0 or 1 is also 0.5 and 1 respectively.\n",
    "\n",
    "The CDF is a useful tool for describing the probability distribution of a random variable because it provides a complete picture of the probabilities associated with that distribution. It allows us to calculate probabilities associated with a specific value or a range of values of the random variable, and it also enables us to compare different probability distributions.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0073204f-2aba-4bd9-a0e3-0bbe406f3c6d",
   "metadata": {},
   "source": [
    "# Q3: What are some examples of situations where the normal distribution might be used as a model?Explain how the parameters of the normal distribution relate to the shape of the distribution.\n",
    "\n",
    "The normal distribution, also known as the Gaussian distribution, is a probability distribution that is widely used as a model in various fields of study, particularly in statistics and natural sciences. It is a continuous distribution that is characterized by its mean (μ) and standard deviation (σ).\n",
    "\n",
    "Some examples of situations where the normal distribution might be used as a model include:\n",
    "\n",
    "Heights or weights of a large population of individuals.\n",
    "IQ scores of a population.\n",
    "Errors in measurements or observations.\n",
    "Stock prices or returns.\n",
    "Reaction times in psychology experiments.\n",
    "The parameters of the normal distribution, μ and σ, determine the shape of the distribution. The mean (μ) determines the location of the distribution, while the standard deviation (σ) determines its spread. Specifically:\n",
    "\n",
    "The mean (μ) is the center of the distribution. It determines the value where the distribution is symmetric and where the peak of the curve is located.\n",
    "The standard deviation (σ) determines the spread or width of the distribution. The larger the value of σ, the more spread out the distribution is, and the flatter the curve appears.\n",
    "The normal distribution is a bell-shaped curve, which means that the curve is symmetrical around its mean. The total area under the curve is equal to 1, and the curve extends from negative infinity to positive infinity. Approximately 68% of the data falls within one standard deviation of the mean, 95% within two standard deviations, and 99.7% within three standard deviations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec273fb-a794-4717-9472-00fef053dd9c",
   "metadata": {},
   "source": [
    "# Q4: Explain the importance of Normal Distribution. Give a few real-life examples of Normal Distribution.\n",
    "\n",
    "The normal distribution, also known as the Gaussian distribution, is an essential concept in statistics and probability theory. It has significant importance in many areas of research, especially in natural sciences, social sciences, and engineering.\n",
    "\n",
    "Here are some of the key reasons why the normal distribution is important:\n",
    "\n",
    "Many real-world phenomena follow the normal distribution. Hence, the normal distribution provides an essential tool for modeling and analyzing data in various fields.\n",
    "It has a straightforward and simple mathematical form that makes it easier to use in statistical calculations and to draw conclusions from the data.\n",
    "The central limit theorem states that the sum or average of a large number of independent and identically distributed (IID) random variables will be approximately normally distributed. This theorem has many practical applications, such as in quality control, finance, and scientific experiments.\n",
    "The normal distribution is widely used in hypothesis testing and statistical inference, allowing us to make predictions about population parameters based on sample data.\n",
    "\n",
    "Here are a few real-life examples of normal distribution:\n",
    "\n",
    "Heights of individuals in a population generally follow a normal distribution, with most people falling close to the average height and fewer people at the extremes.\n",
    "The weights of manufactured items, such as cans of soda, often follow a normal distribution with a mean and standard deviation.\n",
    "IQ scores in a population are normally distributed, with the majority of people falling within one standard deviation of the mean score of 100.\n",
    "In financial markets, stock returns are assumed to be normally distributed, and this assumption is used to model risk and return.\n",
    "Reaction times of individuals to stimuli, such as in psychological experiments, are often modeled by a normal distribution.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0314d7aa-c884-4b1b-82b9-36714a745f54",
   "metadata": {},
   "source": [
    "# Q5: What is Bernaulli Distribution? Give an Example. What is the difference between Bernoulli Distribution and Binomial Distribution?\n",
    "\n",
    "The Bernoulli distribution is a probability distribution that describes a random variable that takes two possible values, typically labeled as 0 and 1. It is named after Swiss mathematician Jacob Bernoulli, who introduced it in the late 17th century. The Bernoulli distribution is a special case of the binomial distribution with n = 1.\n",
    "\n",
    "The probability mass function (PMF) of the Bernoulli distribution is given by:\n",
    "\n",
    "P(X = 1) = p\n",
    "P(X = 0) = 1 - p\n",
    "\n",
    "where X is the random variable, p is the probability of success, and (1 - p) is the probability of failure.\n",
    "\n",
    "An example of the Bernoulli distribution is the flip of a coin, where a head may be considered a success and a tail as a failure. In this case, the probability of success (getting a head) is 0.5, and the probability of failure (getting a tail) is also 0.5.\n",
    "\n",
    "The main difference between the Bernoulli distribution and the binomial distribution is that the Bernoulli distribution models a single trial with two possible outcomes, while the binomial distribution models the number of successes in a fixed number of independent and identically distributed (IID) trials. In other words, the Bernoulli distribution is a special case of the binomial distribution where n = 1.\n",
    "\n",
    "The probability mass function (PMF) of the binomial distribution is given by:\n",
    "\n",
    "P(X = k) = (n choose k) * p^k * (1 - p)^(n-k)\n",
    "\n",
    "where X is the random variable representing the number of successes in n IID trials, p is the probability of success, and (1 - p) is the probability of failure.\n",
    "\n",
    "An example of the binomial distribution is the number of heads obtained when flipping a coin 10 times. Here, n = 10, and p = 0.5 (assuming the coin is fair). The binomial distribution can be used to calculate the probability of obtaining a certain number of heads in these 10 flips."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825f099d-2413-4083-973d-cca8c5b691f0",
   "metadata": {},
   "source": [
    "# Q6. Consider a dataset with a mean of 50 and a standard deviation of 10. If we assume that the dataset is normally distributed, what is the probability that a randomly selected observation will be greater than 60? Use the appropriate formula and show your calculations.\n",
    "\n",
    "Given that the dataset has a mean of 50 and a standard deviation of 10, we can assume that the dataset follows a normal distribution with parameters µ = 50 and σ = 10.\n",
    "\n",
    "To find the probability that a randomly selected observation will be greater than 60, we need to calculate the area under the normal curve to the right of 60.\n",
    "\n",
    "We can use the standard normal distribution table or a calculator to find the corresponding z-score for a value of 60. The z-score is calculated as:\n",
    "\n",
    "z = (x - µ) / σ = (60 - 50) / 10 = 1\n",
    "\n",
    "Using the standard normal distribution table, we can find the area under the curve to the right of z = 1 as 0.1587.\n",
    "\n",
    "Therefore, the probability that a randomly selected observation will be greater than 60 is:\n",
    "\n",
    "P(X > 60) = P(Z > 1) = 0.1587\n",
    "\n",
    "where X is the normally distributed random variable with µ = 50 and σ = 10, and Z is the standard normal random variable with µ = 0 and σ = 1.\n",
    "\n",
    "Thus, the probability of a randomly selected observation being greater than 60 is 0.1587 or approximately 15.87%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2275ed-0c66-435f-871a-a4895f8b8c3c",
   "metadata": {},
   "source": [
    "# Q7: Explain uniform Distribution with an example.\n",
    "\n",
    "The uniform distribution is a probability distribution that describes a random variable with a continuous range of possible values, all of which have an equal probability of occurring. This means that any value within the range is equally likely to occur. It is also known as a rectangular distribution because the probability density function (PDF) is a constant value within the range.\n",
    "\n",
    "The PDF of a uniform distribution with parameters a and b is given by:\n",
    "\n",
    "f(x) = 1 / (b - a) for a ≤ x ≤ b\n",
    "0 otherwise\n",
    "\n",
    "where x is the random variable, a is the lower bound of the range, and b is the upper bound of the range.\n",
    "\n",
    "An example of the uniform distribution is the roll of a fair six-sided die. In this case, the possible values for the random variable are {1, 2, 3, 4, 5, 6}, and each value has an equal probability of occurring. The PDF of the uniform distribution in this case is a horizontal line between x = 1 and x = 6, with a height of 1/6.\n",
    "\n",
    "      |\n",
    "      |        ______\n",
    "  1/6 |_______|      |_______\n",
    "      1       6      x\n",
    "      \n",
    "      \n",
    "Another example of the uniform distribution is the random selection of a number between 0 and 1. In this case, any value between 0 and 1 is equally likely to be selected. The PDF of the uniform distribution in this case is a horizontal line between x = 0 and x = 1, with a height of 1, as shown below:\n",
    "\n",
    "      |\n",
    "      |        ______\n",
    "   1  |_______|      |_______\n",
    "      0       1      x\n",
    "\n",
    "\n",
    "The uniform distribution has many applications in probability theory and statistics, including in Monte Carlo simulations, where it is used to generate random variables within a given range, and in statistical inference, where it is used to represent uncertainty about a parameter that is known to lie within a certain range.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cbf8d5-3a7e-45ca-8c46-7e6194f3cc5a",
   "metadata": {},
   "source": [
    "# Q8: What is the z score? State the importance of the z score.\n",
    "\n",
    "A z-score, also known as a standard score, is a dimensionless number that represents the number of standard deviations an observation or data point is above or below the mean of a distribution. It is calculated by subtracting the mean of the distribution from the data point and then dividing the result by the standard deviation of the distribution.\n",
    "\n",
    "The formula for calculating the z-score is given as:\n",
    "\n",
    "z = (x - µ) / σ\n",
    "\n",
    "where z is the z-score, x is the data point, µ is the mean of the distribution, and σ is the standard deviation of the distribution.\n",
    "\n",
    "The importance of the z-score lies in its ability to standardize different distributions and enable comparisons between them. By transforming raw data into z-scores, we can compare observations from different distributions that have different scales and units of measurement. For example, we can use z-scores to compare the height of male and female students in a school, even though their heights may be measured in different units (e.g. centimeters versus inches).\n",
    "\n",
    "Z-scores are also used in hypothesis testing and statistical inference to determine whether an observation or data point is statistically significant or not. By comparing the z-score of an observation to a standard normal distribution, we can determine the probability or p-value of obtaining a value as extreme or more extreme than the observation. If the p-value is small enough (typically less than 0.05), we can reject the null hypothesis and conclude that the observation is statistically significant.\n",
    "\n",
    "Overall, the z-score is an important statistical tool that allows us to compare and analyze data from different distributions and make inferences about populations based on samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cbb0b2-50cb-4ba1-832d-e8f571d2419b",
   "metadata": {},
   "source": [
    "\n",
    "# Q9: What is Central Limit Theorem? State the significance of the Central Limit Theorem.\n",
    "\n",
    "The central limit theorem (CLT) is a fundamental theorem in statistics that states that the sum or average of a large number of independent and identically distributed (iid) random variables will tend towards a normal distribution, regardless of the original distribution of the random variables. This means that as the sample size increases, the distribution of the sample mean or sum becomes more and more normal, even if the original population is not normally distributed.\n",
    "\n",
    "The central limit theorem is important because it provides a theoretical foundation for many statistical techniques, such as hypothesis testing, confidence intervals, and regression analysis, which rely on the assumption of normality or near-normality of the data. In practice, it means that even if we don't know the true underlying distribution of a population, we can still use the normal distribution as an approximation, as long as our sample size is large enough.\n",
    "\n",
    "The central limit theorem has several key implications:\n",
    "\n",
    "Large sample sizes are generally preferred for statistical analysis because they tend to produce more accurate estimates and better approximations of the true population parameters.\n",
    "\n",
    "The normal distribution is a versatile and useful distribution for modeling many natural phenomena, due to its prevalence in the central limit theorem.\n",
    "\n",
    "Even if the original distribution is highly skewed or non-normal, the sample mean or sum will tend towards a normal distribution as the sample size increases.\n",
    "\n",
    "Overall, the central limit theorem is a powerful tool in statistics that underpins many important statistical concepts and methods. It enables us to make statistical inferences and draw conclusions about populations based on samples, even when we don't know the true underlying distribution of the population."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc351bf0-ddd8-48e4-8a69-4d9239095196",
   "metadata": {},
   "source": [
    "# Q10: State the assumptions of the Central Limit Theorem.\n",
    "\n",
    "\n",
    "The central limit theorem (CLT) makes several assumptions to hold true. These assumptions include:\n",
    "\n",
    "Random Sampling: The sample is chosen randomly from a population, and each observation in the sample is independent of the others.\n",
    "\n",
    "Independence: The observations in the sample are independent of each other, meaning that the value of one observation does not affect the value of any other observation.\n",
    "\n",
    "Sample Size: The sample size is sufficiently large. While there is no hard and fast rule for what constitutes a \"large\" sample size, a commonly cited rule of thumb is that the sample size should be at least 30.\n",
    "\n",
    "Finite Variance: The population from which the sample is drawn has a finite variance. This means that the variability of the population is not infinite.\n",
    "\n",
    "If these assumptions are met, the central limit theorem states that the sample mean will follow a normal distribution with a mean equal to the population mean and a standard deviation equal to the population standard deviation divided by the square root of the sample size. This result is very useful in practice, as it allows us to make statistical inferences and draw conclusions about populations based on samples, even when the population distribution is not known or is highly skewed or non-normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe6cf05-d6da-4141-9f2d-4bcbe607d681",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
